{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZTRygmKm+DXziW4DDXz8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ambikad04/FL-PrivacyPreserving-HealthcareAnalytics/blob/main/PrivacyPreserving_HealthcareAnalytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "S2vKl1aRZtXV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Fully Connected Model for Tabular Data\n",
        "class FCModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(FCModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))  # Output layer for binary classification\n",
        "        return x"
      ],
      "metadata": {
        "id": "9Ez3YkOkZ5nX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Synthetic Data (Healthcare)\n",
        "X, y = make_classification(n_samples=100, n_features=10, n_informative=8, n_classes=2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "bGZrTe8NaIg_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate Client Data (Split data into 5 clients)\n",
        "clients_data = [(torch.tensor(X_train[i:i+20], dtype=torch.float32), torch.tensor(y_train[i:i+20], dtype=torch.float32)) for i in range(0, 80, 20)]\n",
        "clients_data_test = [(torch.tensor(X_test[i:i+5], dtype=torch.float32), torch.tensor(y_test[i:i+5], dtype=torch.float32)) for i in range(0, 20, 5)]"
      ],
      "metadata": {
        "id": "EkM8IbbEbWyF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Local Model on Each Client\n",
        "def train_local_model(model, data, targets, epochs=5):\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs.squeeze(), targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return model.state_dict()"
      ],
      "metadata": {
        "id": "-2kxYqOZaQV3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Federated Averaging (with Personalization)\n",
        "def federated_averaging_with_personalization(global_model, local_models_weights, personalization_factor=0.1):\n",
        "    global_state_dict = global_model.state_dict()\n",
        "    for key in global_state_dict:\n",
        "        global_state_dict[key] = torch.mean(torch.stack([local_weights[key] for local_weights in local_models_weights]), dim=0)\n",
        "        for local_weights in local_models_weights:\n",
        "            global_state_dict[key] = global_state_dict[key] * (1 - personalization_factor) + local_weights[key] * personalization_factor\n",
        "    global_model.load_state_dict(global_state_dict)"
      ],
      "metadata": {
        "id": "mPwij4AtbgBq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Global Model\n",
        "input_dim = X_train.shape[1]  # Number of features in the dataset\n",
        "global_model = FCModel(input_dim)\n"
      ],
      "metadata": {
        "id": "XXgQ2Ow9aW-v"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Federated Learning Process (10 rounds)\n",
        "for round in range(10):\n",
        "    print(f\"Round {round + 1}\")\n",
        "    local_models_weights = []\n",
        "\n",
        "    # Each client trains on its local data\n",
        "    for client_data, client_targets in clients_data:\n",
        "        local_model = FCModel(input_dim)\n",
        "        local_model.load_state_dict(global_model.state_dict())  # Initialize with global model weights\n",
        "        local_weights = train_local_model(local_model, client_data, client_targets)\n",
        "        local_models_weights.append(local_weights)\n",
        "\n",
        "    # Federated Averaging with Personalization\n",
        "    federated_averaging_with_personalization(global_model, local_models_weights)\n",
        "\n",
        "    # Testing the model on client data (optional)\n",
        "    global_model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for client_data, client_targets in clients_data_test:\n",
        "            outputs = global_model(client_data)\n",
        "            predicted = (outputs.squeeze() > 0.5).float()\n",
        "            total += client_targets.size(0)\n",
        "            correct += (predicted == client_targets).sum().item()\n",
        "        accuracy = correct / total\n",
        "        print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzAegcenbni_",
        "outputId": "d6b6cf2e-750c-428b-bd88-1ba8c39fa1f6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1\n",
            "Test Accuracy: 45.00%\n",
            "Round 2\n",
            "Test Accuracy: 45.00%\n",
            "Round 3\n",
            "Test Accuracy: 45.00%\n",
            "Round 4\n",
            "Test Accuracy: 50.00%\n",
            "Round 5\n",
            "Test Accuracy: 50.00%\n",
            "Round 6\n",
            "Test Accuracy: 55.00%\n",
            "Round 7\n",
            "Test Accuracy: 60.00%\n",
            "Round 8\n",
            "Test Accuracy: 65.00%\n",
            "Round 9\n",
            "Test Accuracy: 70.00%\n",
            "Round 10\n",
            "Test Accuracy: 70.00%\n",
            "Training complete.\n"
          ]
        }
      ]
    }
  ]
}